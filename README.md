# EQWorks-Application

In this repo there are two parts, the first general part of the application (the Jupyter notebook file), and the second data engineering specific part (the python file)

For the general part I choose to work in Spark and completed both questions.

For the data engineering specific part of the take application, not all of it is complete so there is no need to have an engineer properly test it. The only things that have been changed are the DB variables (DB_HOST, DB_PORT, etc...) , the dag and task args, and the dependencies. It does load into Airflow properly without error but the tasks are empty.

I look forward to hearing from the EQWorks team about either the data engineer or the developer internship positions.
